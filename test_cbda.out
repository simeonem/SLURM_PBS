
R version 3.5.0 (2018-04-23) -- "Joy in Playing"
Copyright (C) 2018 The R Foundation for Statistical Computing
Platform: x86_64-apple-darwin15.6.0 (64-bit)

R是自由软件，不带任何担保。
在某些条件下你可以将其自由散布。
用'license()'或'licence()'来看散布的详细条件。

R是个合作计划，有许多人为之做出了贡献.
用'contributors()'来看合作者的详细情况
用'citation()'会告诉你如何在出版物中正确地引用R或R程序包。

用'demo()'来看一些示范程序，用'help()'来阅读在线帮助文件，或
用'help.start()'通过HTML浏览器来看帮助文件。
用'q()'退出R.

[原来保存的工作空间已还原]

> library(CBDA)
> 
> # Accepting parameters from command line(or a PBS file when using flux)
> args <- commandArgs(TRUE)
> for(i in 1:length(args))
+     {
+     	#The printed value will be the parameters; you can use them in the R file.
+         print(eval(parse(text=args[[i]])))
+     }
[1] 1
[1] 2 5 6
> print("Parameters Received Succesfully.")
[1] "Parameters Received Succesfully."
> 
> # Installation
> # Please upload the Windows binary and/or source CBDA_1.0.0 files from
> # the CBDA Github repository https://github.com/SOCR/CBDA/releases
> 
> # Initialization
> # This function call installs (if needed) and attaches all the necessary packages to run
> # the CBDA package v1.0.0. It should be run before any production run or test.
> # The output shows a table where for each package a TRUE or FALSE is displayed.
> # Thus the necessary steps can be pursued in case some package has a FALSE.
> CBDA_initialization()
package missForest already installed
package stats already installed
package utils already installed
package prettydoc already installed
package foreach already installed
package SuperLearner already installed
package knockoff already installed
package caret already installed
package smotefamily already installed
package parallel already installed
package doParallel already installed
package glmnet already installed
Loading required package: missForest
Loading required package: randomForest
randomForest 4.6-14
Type rfNews() to see new features/changes/bug fixes.
Loading required package: foreach
Loading required package: itertools
Loading required package: iterators
Loading required package: prettydoc
Loading required package: SuperLearner
Loading required package: nnls
Super Learner
Version: 2.0-23
Package created on 2018-03-09

Loading required package: knockoff
Loading required package: caret
Loading required package: lattice
Loading required package: ggplot2

Attaching package: ‘ggplot2’

The following object is masked from ‘package:randomForest’:

    margin

Loading required package: smotefamily
Loading required package: parallel
Loading required package: doParallel
Loading required package: glmnet
Loading required package: Matrix
Loaded glmnet 2.0-16

  missForest        stats        utils    prettydoc      foreach SuperLearner 
        TRUE         TRUE         TRUE         TRUE         TRUE         TRUE 
    knockoff        caret  smotefamily     parallel   doParallel       glmnet 
        TRUE         TRUE         TRUE         TRUE         TRUE         TRUE 
> 
> # Set the specs for the synthetic dataset to be tested
> n = 300          # number of observations
> p = 100          # number of variables
> 
> # Generate a nxp matrix of IID variables (e.g., ~N(0,1))
> X1 = matrix(rnorm(n*p), nrow=n, ncol=p)
> 
> # Setting the nonzero variables - signal variables
> nonzero=c(1,100,200,300,400,500,600,700,800,900)
> 
> # Set the signal amplitude (for noise level = 1)
> amplitude = 10
> 
> # Allocate the nonzero coefficients in the correct places
> beta = amplitude * (1:p %in% nonzero)
> 
> # Generate a linear model with a bias (e.g., white  noise ~N(0,1))
> ztemp <- function() X1 %*% beta + rnorm(n)
> z = ztemp()
> 
> # Pass it through an inv-logit function to
> # generate the Bernoulli response variable Ytemp
> pr = 1/(1+exp(-z))
> Ytemp = rbinom(n,1,pr)
> X2 <- cbind(Ytemp,X1)
> 
> dataset_file ="Binomial_dataset_3.txt"
> 
> # Save the synthetic dataset
> a <- tempdir()
> write.table(X2, file = paste0(file.path(a),'/',dataset_file), sep=",")
> 
> # The file is now stored in the directory a
> a
[1] "/var/folders/38/cjnjrxts7_z1lm3ydmfxx4_40000gp/T//Rtmp2AGys8"
> list.files(a)
[1] "Binomial_dataset_3.txt"
> 
> # Load the Synthetic dataset
> Data = read.csv(paste0(file.path(a),'/',dataset_file),header = TRUE)
> Ytemp <- Data[,1] # set the outcome
> original_names_Data <- names(Data)
> cols_to_eliminate=1
> Xtemp <- Data[-cols_to_eliminate] # set the matrix X of features/covariates
> original_names_Xtemp <- names(Xtemp)
> 
> # Add more wrappers/algorithms to the SuperLearner ensemble predictor
> # It can be commented out if only the default set of algorithms are used,
> # e.g., algorithm_list = c("SL.glm","SL.xgboost","SL.glmnet","SL.svm",
> #                          "SL.randomForest","SL.bartMachine")
> # This defines a "new" wrapper, based on the default SL.glmnet
> SL.glmnet.0.75 <- function(..., alpha = 0.75,family="binomial"){
+   SL.glmnet(..., alpha = alpha, family = family)}
> 
> test_example <- c("SL.glmnet","SL.glmnet.0.75")
> 
> # Call the Main CBDA function
> # Multicore functionality NOT enabled
> CBDA_object <- CBDA(Ytemp , Xtemp , M = 12 , Nrow_min = 50, Nrow_max = 70,
+                     top = 10, max_covs = 8 , min_covs = 3,algorithm_list = test_example ,
+                     workspace_directory = a)
Subsampling size =  12 

Case Sampling Range - CSR (%) =  50_70 %

Feature Sampling Range - FSR (%) =  5_15 %

Learning/Training steps initiated successfully !!
Completion %
8.33333333333333
Completion %
16.6666666666667
Completion %
25
Completion %
33.3333333333333
Completion %
41.6666666666667
Completion %
50
Completion %
58.3333333333333
Completion %
66.6666666666667
Completion %
75
Completion %
83.3333333333333
Completion %
91.6666666666667
Completion %
100
Learning/Training steps completed successfully !!

CONSOLIDATION STEP HAS STARTED !!

[1] "Loading workspace: 1"
[1] "Loading workspace: 2"
[1] "Loading workspace: 3"
[1] "Loading workspace: 4"
[1] "Loading workspace: 5"
[1] "Loading workspace: 6"
[1] "Loading workspace: 7"
[1] "Loading workspace: 8"
[1] "Loading workspace: 9"
[1] "Loading workspace: 10"
[1] "Loading workspace: 11"
[1] "Loading workspace: 12"
Learning/Training Table with Top features
 Accuracy Count Density  MSE Count Density 
 78       4     4.210526 72  4     3.883495
 53       3     3.157895 78  4     3.883495
 72       3     3.157895 20  3     2.912621
 74       3     3.157895 53  3     2.912621
 76       3     3.157895 63  3     2.912621
 4        2     2.105263 74  3     2.912621
 5        2     2.105263 76  3     2.912621
 9        2     2.105263 89  3     2.912621
Consolidated workspace successfully created.

Subsample workspaces successfully deleted.

Consolidation completed successfully !!

VALIDATION STEP for TOP nested predictive models has started.

Subsampling size =  12 

Case Sampling Range - CSR (%) =  50_70 %

Feature Sampling Range - FSR (%) =  5_15 %

Completion %
16.6666666666667
Completion %
33.3333333333333
Completion %
50
Completion %
66.6666666666667
Completion %
83.3333333333333
Completion %
100
Validation workspace successfully created.

VALIDATION STEP COMPLETED SUCCESSFULLY !!

STOPPING cRITERIA GENERATION STEP HAS STARTED !!
Performance metrics for the nested Predictive models.
VALIDATION TABLE
  NumberOfTopFeatures Inference_Acc Inference_MSE StopAcc StopMSE
1                   3           0.5     0.2551913    Stop    Stop
2                   4           0.5     0.2541667    Stop    Stop
3                   5           0.5     0.2543650    Stop    Stop
4                   6           0.5     0.2497422    Stop    Stop
5                   7           0.5     0.2569513    Stop    Stop
6                   8           0.5     0.2541667      NA      NA


Stopping Criteria completed successfully !!

Clean up started !!

Clean up completed successfully !!There were 12 warnings (use warnings() to see them)
> 
> # Multicore functionality enabled
> #test_example <- c("SL.xgboost","SL.svm")
> #CBDA_test <- CBDA(Ytemp , Xtemp , M = 40 , Nrow_min = 50, Nrow_max = 70,
> #                  N_cores = 2 , top = 30, max_covs = 20 ,
> #                  min_covs = 5 , algorithm_list = test_example ,
> #                  workspace_directory = a)
> 
> ## End(Not run)
> 
> proc.time()
  用户   系统   流逝 
43.353  2.920 45.488 
